=====
CEPH + CoprHD CheatSheet:
++++ Login to the CoprHD Node:
`vagrant ssh coprhd -- -l storageos`  # P: vagrant
Set these variables:
`export COPRHD_HOST=192.168.100.11`
`export VIPR_HOSTNAME=${COPRHD_HOST}`

# 0) Get Ceph Admin Key:
ssh 192.168.100.100 -l vagrant "cat /etc/ceph/ceph.client.admin.keyring"
P: vagrant

# 1) Authenticate
/opt/storageos/cli/bin/viprcli authenticate -u root -d /tmp
P should be: "ChangeMe" unless you've changed it through CoprHD Portal

# 2) Add Ceph as Storage Provider
/opt/storageos/cli/bin/viprcli storageprovider create -n CEPH -provip 192.168.100.100 -provport 22 -u admin -if ceph
[ Use Key from Step 0 as password ]

# 3) Verify Ceph StorageSystem exists
/opt/storageos/cli/bin/viprcli storagesystem list

# 4) Add IP Network for Ceph
/opt/storageos/cli/bin/viprcli network create -n CephIP -t IP

# 5) Add Virtual Array
/opt/storageos/cli/bin/viprcli varray create -n myVarray1

# 6) Add Virtual Array to Network
/opt/storageos/cli/bin/viprcli network update -varray_add myVarray1 -n CephIP

# 7) Get Ceph System ID
/opt/storageos/cli/bin/viprcli storagesystem list
[Copy the "Name" Field to be used as CEPH_ID]

# 8) Check Ceph's Storage Port
/opt/storageos/cli/bin/viprcli storageport list -t ceph -storagesystem [CEPH_ID]
[Get the PORT_NETWORK_ID field for the CEPH_Storage_Port_ID]

# 9) Add Storage Port to Network
/opt/storageos/cli/bin/viprcli network update -n CephIP -endpoint_add [CEPH_Storage_Port_ID]

# 10) Create a Block Vpool and attach to Ceph VA
/opt/storageos/cli/bin/viprcli vpool create -systemtype ceph -type block -n ThinCeph -protocol RBD -va myVarray1 -pt Thin -desc CephVP

# 11) Create a Project
/opt/storageos/cli/bin/viprcli project create -n CephProj

# 12) Add Host to CoprHD (RHEL 7.2 has been tested)
/opt/storageos/cli/bin/viprcli host create -type Linux -hl Rhel -hn 192.168.100.72 -un root
[Enter root password to the RHEL box (make sure RHEL box has PermitRootLogin enabled in sshd_config]

# 13) Get host initiator name
/opt/storageos/cli/bin/viprcli host list-initiators -hl Rhel

# 14) Add Host initiator to CephIP Network
/opt/storageos/cli/bin/viprcli network update -n CephIP -endpoint_add rbd:5f2123b2d1cd407e863a1ff9539a148b

# 15) Create a Ceph Volume:
/opt/storageos/cli/bin/viprcli volume create -n CephVol -size 1G -pr CephProj -vpool ThinCeph -va myVarray1

# 16) Create an Export Group:
/opt/storageos/cli/bin/viprcli exportgroup create -n 192.168.100.72 -pr CephProj -varray myVarray1 -type Host

# 17) Get the Initiator Port for Host:
/opt/storageos/cli/bin/viprcli initiator list -hl Rhel

# 18) Add Host Initiator to the ExportGroup:
/opt/storageos/cli/bin/viprcli exportgroup add_initiator -name 192.168.100.72 -in [INITIATOR_PORT from previous command] -hl Rhel -pr CephProj

# 19) Add Created Volume to Export Group:
/opt/storageos/cli/bin/viprcli exportgroup add_vol -n 192.168.100.72 -volume CephVol -pr CephProj

++++ From your Vagrant/Virtualbox host, go to the Ceph Node 
`vagrant ssh mon`
# Check Ceph is running
ceph status
# Confirm Volume is created in Ceph
rbd ls -l # Watch volumes come in and out

After steps above, should see this volume:
NAME                                          SIZE PARENT FMT PROT LOCK
CephVol:d756117b-7d6d-4cca-9868-4e1cad8210cd 1024M          2
(Unique ID will be different, but first part 'CephVol' will be same)

++++ To Remove Export and Volume:
++++ Back on the CoprHD Node:
# 20) Remove Export Group:
/opt/storageos/cli/bin/viprcli exportgroup delete -n 192.168.100.72 -pr CephProj

# 21) Delete Ceph Volume:
/opt/storageos/cli/bin/viprcli volume delete -n CephVol -pr CephProj
